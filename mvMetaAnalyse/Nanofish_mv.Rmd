---
title: "Nanofish_mv"
author: "Querusche"
date: "2024"
output:
  pdf_document: default
  html_document: default
  df_print: paged
editor_options: 
  markdown: 
    wrap: 72
---

## Tutorials from:
-   Y. Yang, M. Macleod, J. Pan, M. Lagisz, S. Nakagawa, 2023. Advanced methods
    and implementations for the meta-analyses of animal models: current 
    practices and future recommendations. Neurosci. Biobehav. Rev., 146
    <https://doi.org/10.1016/j.neubiorev.2022.105016>

-   Yefeng Yang, Malcom Macleaod, Jinming Pan, Malgorzata Lagisz,
    Shinichi Nakagawa, 2022. The current practices of meta-analyses
    using animal models, and underappreciated opportunities using
    advanced methods: multilevel models and robust variance estimation.
    Neuroscience & Biobehavioral Reviews.
    <https://doi.org/10.1016/j.neubiorev.2022.105016>

-   Wolfgang Viechtbauer <https://www.metafor-project.org>
    <https://wviechtb.github.io/metafor/reference/misc-recs.html>
    <https://wviechtb.github.io/meta_analysis_books/>
    
-   Shinichi Nakagawa, Malgorzata Lagisz, Rose E. Oâ€™Dea, Patrice Pottier, Joanna Rutkowska, Alistair M. Senior, Yefeng Yang, Daniel W.A. Noble. 2023. orchaRd 2.0: An R package for visualizing meta-analyses with orchard plots. Methods in Ecology and Evolution, https://doi.org/10.1111/2041-210X.14152 (preprint = EcoEvoRxiv, https://doi.org/10.32942/X2QC7). <https://daniel1noble.github.io/orchaRd/>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")

#devtools::install_github("daniel1noble/orchaRd", ref = "main", force = TRUE)
#pacman::p_load(devtools, tidyverse, metafor, patchwork, R.rsp, orchaRd, emmeans,
#    ape, phytools, flextable)

library(clubSandwich)
library(GGally)
library(ggplot2)
library(grid)
library(gridExtra)
library(pacman)
library(metafor)
library(dplyr)
library(tidyverse)
library(gt) # https://posit.co/blog/great-looking-tables-gt-0-2/

```

## Preparing data

1 - load data 2 - configures factor and numeral variables 3 -
transformations of numeral variables

NA = not applicable Unclear = unavailable information on the paper

```{r Load data, echo=FALSE}

source("functions_Nanofish.R",encoding = "UTF-8")
m = vector("list",2)
names(m) <- c("null","forest")

df_original<-load_prep_df("mvMetaAnalysis.csv")

datainfo <- summary(df_original)
# write.table(datainfo, "mvMetaAnalyse/descriptives.txt", sep="\t")

variables <- variable.names(df_original)
outcomeslist = sort(unique(df_original$Outcome))
moderatorslist = c(   "Species",
                      "Sex",
                      "DevelopmentalStage",
                      "ParticleMaterial", 
                      "ParticleShape", 
                      "ParticleSizeMean",
                      "AdministrationRoute", 
                      "Concentration_mg_L",
                      "ExposureDurationDays")

outcomeslist
moderatorslist
```

## Calculate effect size

"SMD" for the standardized mean difference (Hedges, 1981) "SMDH" for the
standardized mean difference with heteroscedastic population variances
in the two groups (Bonett, 2008, 2009)

UB = to compute unbiased estimates of the sampling variances (equation 9
in Hedges, 1983)

```{r}
df_original <- escalc(measure = "SMD", 
             n1i = n_treat, #n of treatment group
             n2i = n_ctrl, #n of control group
             m1i = mean_treat, #mean of treatment group 
             m2i = mean_ctrl, #mean of control group
             sd1i = STD_treat, #sd of treatment group
             sd2i = STD_ctrl, #sd of control group
             data = df_original, vtype = "UB") 
# write.table(df_original, "mvMetaAnalyse/mvMetaAnalysis_SMDs.txt", sep="\t")
```

## Descriptives plots

```{r echo=FALSE}
#ggpairs(df_original, mapping = aes(color = Shape, alpha = 0.3), columns = moderatorslist,title = "")
pdf(file='Figures/Boxplot_ESbyOutcome.pdf') # Open SVG device with specific file name
df_original %>%
  mutate(class = factor(Outcome, levels = rev(levels(Outcome)))) %>%
  ggplot( aes(yi, class, fill=class))+ 
    geom_boxplot() +
    xlab("ES") + 
    ylab("") +
    theme_bw(base_size = 18) +
    theme(legend.position="none")
set_plot_dimensions(7, 7)
 dev.off()
```

## Null model and data inspection through forest plot

In order to detect anomalies on the data and review the data bank, when
necessary, first one null model was elaborated for each variable folowed
by their respective forest plot.
<https://wviechtb.github.io/metafor/reference/forest.rma.html>

```{r, echo=FALSE, warning=FALSE}

n_outcome = 1
for(n_outcome in sequence(nlevels(outcomeslist)))
{
outcome<-as.character(outcomeslist[n_outcome])
df <- df_original[ which(df_original$Outcome == outcome ),]
df <- df[order(df$DevelopmentalStage,-df$yi),]

### fit random-effects null model
m$null[[outcome]] <- rma.mv(yi, vi, 
                                data=df, 
                                method="ML")

m$forest[[outcome]]<-forest_plot(m$null[[outcome]],outcome,"NULLmodel")
}
```


# Likelihood ratio tests and Profile Likelihood Plots of sigma

## Model comparison for appropriete random-effect structure: Likelihood ratio tests

Random effects candidates: - Effect size cluster - Study - Study cluster
OBS: when using AIC criteria use maximum likelihood (ML) rather than
restricted maximum likelihood (REML)

```{r, echo=FALSE}
# create variable to store random effects model
resRF.ExpID =        vector("list",nlevels(outcomeslist))
resRF.StudyID =      vector("list",nlevels(outcomeslist))
resRF.StudyCluster = vector("list",nlevels(outcomeslist))
resRF.StudyIDExpID = vector("list",nlevels(outcomeslist))
resRF.StudyClusterStudyIDExpID = vector("list",nlevels(outcomeslist))

# run model, inspect results, select model random effects structure for each variable, then plot the profile for each random effect included.
for(outcome in outcomeslist)
  {
df <- df_original[ which(df_original$Outcome==outcome ),]
df <-df[order(df$DevelopmentalStage,-df$yi),]

resRF.ExpID[[outcome]] <- rma.mv(yi, vi, 
            random = list(~ 1 | EScluster), 
            data=df, 
            method="ML")
resRF.StudyID[[outcome]] <- rma.mv(yi, vi, 
            random = ~ 1 | Study, 
            data=df, 
            method="ML")
resRF.StudyCluster[[outcome]] <- rma.mv(yi, vi, 
            random = ~ 1 | StudyCluster, 
            data=df, 
            method="ML")
resRF.StudyIDExpID[[outcome]] <- rma.mv(yi, vi, 
            random = ~ 1 | Study/EScluster, 
            data=df, 
            method="ML")
resRF.StudyClusterStudyIDExpID[[outcome]] <- rma.mv(yi, vi, 
            random = ~ 1 | StudyCluster/Study/EScluster, 
            data=df, 
            method="ML")
}
rm("df")

# Inspect Results
## create table of results
columns = c("LRT 1","pval 1","LRT 2","pval 2","LRT 3","pval 3","LRT 4","pval 4","LRT 5","pval 5","LRT 6","pval 6") 
rst_tbl_RF = data.frame(matrix(nrow = length(outcomeslist), ncol = length(columns))) 
colnames(rst_tbl_RF) = columns
rownames(rst_tbl_RF) = outcomeslist

## run analysis
for(outcome in outcomeslist)
  {
anova1.ExpID_null           <- anova.rma(resRF.ExpID[[outcome]], m$null[[outcome]])
anova2.StudyID_null         <- anova.rma(resRF.StudyID[[outcome]],m$null[[outcome]])
anova3.StudyCluster_null    <- anova.rma(resRF.StudyCluster[[outcome]],m$null[[outcome]])
anova4.StudyIDExpID_ExpID   <- anova.rma(resRF.StudyIDExpID[[outcome]], resRF.ExpID[[outcome]])
anova5.StudyIDExpID_StudyID <- anova.rma(resRF.StudyIDExpID[[outcome]], resRF.StudyID[[outcome]])
anova6.Full_StudyIDExpID    <- anova.rma(resRF.StudyClusterStudyIDExpID[[outcome]],resRF.StudyIDExpID[[outcome]])

rst_tbl_RF[outcome,] = round(c(anova1.ExpID_null$LRT,          anova1.ExpID_null$pval, 
                                anova2.StudyID_null$LRT,         anova2.StudyID_null$pval,
                                anova3.StudyCluster_null$LRT,    anova3.StudyCluster_null$pval,
                                anova4.StudyIDExpID_ExpID$LRT,   anova4.StudyIDExpID_ExpID$pval,
                                anova5.StudyIDExpID_StudyID$LRT, anova5.StudyIDExpID_StudyID$pval,
                                anova6.Full_StudyIDExpID$LRT,    anova6.Full_StudyIDExpID$pval),3)}
Outcome = outcomeslist
rst_tbl_RF = cbind(Outcome,rst_tbl_RF)

gt(rst_tbl_RF,rowname_col = "Outcome",) %>%
tab_source_note( "1 = Exp. vs Null,
                 2 = Study vs Null,
                 3 = Cluster vs Null,
                 4 = Study+Exp. vs Exp.,
                 5 = Study+Exp. vs Study,
                 6 = Cluster+Study+Exp. vs Study+Exp.") %>%
cols_align(align = "right", columns = 2:13)%>%
cols_align(align = "left", columns = 1)

rm(list = ls(pat = "anova"))
```

```{r, echo=TRUE}
## keep chosen Random Effects model
for(outcome in outcomeslist)
{
  switch(outcome, 
  {m$random_effects[[outcome]] <- resRF.StudyIDExpID[[outcome]]  },     # n_outcome = 1 (Study and EScluster) # Neurochemical outcomes: AChE activity
  {m$random_effects[[outcome]] <- resRF.StudyIDExpID[[outcome]]  },     # n_outcome = 2 (Study only possible) # Neurochemical outcomes: CAT activity
  {m$random_effects[[outcome]] <- resRF.StudyIDExpID[[outcome]]  },     # n_outcome = 3 (Study and EScluster) # Neurochemical outcomes: GPx activity
  {m$random_effects[[outcome]] <- resRF.StudyIDExpID[[outcome]]  },     # n_outcome = 4 (Study only possible) # Neurochemical outcomes: GSH content
  {m$random_effects[[outcome]] <- resRF.StudyIDExpID[[outcome]]  },     # n_outcome = 5 (Study only possible) # Neurochemical outcomes: GST activity
  {m$random_effects[[outcome]] <- resRF.StudyIDExpID[[outcome]]  },     # n_outcome = 6 (Study only possible) # Neurochemical outcomes: Lipid peroxidation
  {m$random_effects[[outcome]] <- resRF.StudyIDExpID[[outcome]]  },     # n_outcome = 7 (Study only possible) # Neurochemical outcomes: ROS levels
  {m$random_effects[[outcome]] <- resRF.StudyIDExpID[[outcome]]  },     # n_outcome = 8 (Study only possible) # Neurochemical outcomes: SOD activity
  {m$random_effects[[outcome]] <- resRF.StudyIDExpID[[outcome]]  },     # n_outcome = 9 (Study only possible) # Motor function: Distance
  {m$random_effects[[outcome]] <- resRF.StudyIDExpID[[outcome]]  },     # n_outcome = 10 (Study and EScluster) # Sensory-motor function: Distance
  {m$random_effects[[outcome]] <- resRF.StudyIDExpID[[outcome]]  },     # n_outcome = 11 (null model possible) # Feeding behaviour: Predatory performance
  {m$random_effects[[outcome]] <- resRF.StudyID[[outcome]]  },          # n_outcome = 12 (Is a Study only analysis) # Feeding behaviour: Feeding time
  {m$random_effects[[outcome]] <- resRF.StudyID[[outcome]]  })          # n_outcome = 13 (Is a Study only analysis) # Feeding behaviour: Speed during feeding
}
rm(list = ls(pat = "resRF"))

# for data evaluation
# a <- df_original[df_original$Outcome == "Neurochemical outcomes: GST activity",c("StudyCluster","Study","EScluster")]
# a
```

## Are the variance components identifiable? Profile Likelihood Plots

When profile likelihood plots are peaked at the respective parameter
estimates and the log likelihoods quickly decrease (i.e., become more
negative) as the values of the components are moved away from the actual
REML estimates, it shows that that the variance component is
identifiable. When there are missing points the model did not converge
for some of the profile points. When large parts of the profiles are
flat, indicates that the model is overparameterized.

"Profile likelihood plots of the variance components are shown in Figure
A (Model 1) and Figure B (Model 2). In this procedure, Ïƒ_1\^2 (variance
at the study level) and Ïƒ_2\^2 (variance at the sample level) were fixed
at different values (i.e., all the positions of the dots on the x-axis).
For each value of Ïƒ_1\^2 and Ïƒ_2\^2, the (logarithm of the) likelihood
over the remaining model parameters, such as the fixed effects, was
estimated (Viechtbauer, 2010). This means it was estimated how likely
the values of these parameters are given the observed data. Less
negative values of the logarithm indicate a higher likelihood than more
negative values. It can be seen that the likelihood was estimated to be
the highest for the values of Ïƒ_1\^2 and Ïƒ_2\^2 that had been estimated
in the original models (0.31 and 0.21 for Model 1, and 0.49 and 0.05 for
Model 2). This, and also the fact that the log-likelihoods become more
negative as the values of Ïƒ2 move away from the parameter estimates,
suggest that we can be "fairly confident" that our meta-analytic models
could identify the variance components (Viechtbauer, 2017)."

```{r, echo=FALSE,fig.height=6, fig.width=3}

for(n_outcome in sequence(nlevels(outcomeslist)))
{
  pdf(file=paste('Figures/Profile likelihood plot_',n_outcome,'_',
                  outcomeslist[n_outcome],'.pdf',sep=""),paper="A4")
  
  switch(length(res.random_effects[[n_outcome]]$sigma2), 
       
  {par(mfrow=c(3,1))
    profile(res.random_effects[[n_outcome]] , sigma2=1)
    title(sub = "Study",cex.sub = 1)
    mtext(outcomeslist[n_outcome],cex=0.6,side = 3, line = -1.2, outer = TRUE)},
    
  {par(mfrow=c(3,1))
    profile(res.random_effects[[n_outcome]] , sigma2=1)
    title(sub = "Study",cex.sub = 1)
    profile(res.random_effects[[n_outcome]] , sigma2=2)
    title(sub = "ES cluster",cex.sub = 1)
    mtext(outcomeslist[n_outcome],cex=0.6,side = 3, line = -1.2, outer = TRUE)},
  
  {par(mfrow=c(3,1))
   profile(res.random_effects[[n_outcome]] , sigma2=1)
    title(sub = "Study",cex.sub = 1)
    profile(res.random_effects[[n_outcome]] , sigma2=2)
    title(sub = "Study",cex.sub = 1)
    profile(res.random_effects[[n_outcome]] , sigma2=3)
    title(sub = "ES cluster",cex.sub = 1)
    mtext(outcomeslist[n_outcome],cex=0.6,side = 3, line = -1.2, outer = TRUE)})

  dev.off()
   }
```

## Random Effects formula for each variable

```{r, echo=TRUE}
random_factors = list(formula(~1 | Study/EScluster),              # n_outcome = 1,
                      formula(~1 | Study/EScluster),              # n_outcome = 2,
                      formula(~1 | Study/EScluster),              # n_outcome = 3,
                      formula(~1 | Study/EScluster),              # n_outcome = 4,
                      formula(~1 | Study/EScluster),              # n_outcome = 5,
                      formula(~1 | Study/EScluster),              # n_outcome = 6,
                      formula(~1 | Study/EScluster),              # n_outcome = 7, 
                      formula(~1 | Study/EScluster),              # n_outcome = 8,
                      formula(~1 | Study/EScluster),              # n_outcome = 9,
                      formula(~1 | Study/EScluster),              # n_outcome = 10,
                      formula(~1 | Study/EScluster),              # n_outcome = 11,
                      formula(~1 | Study),                        # n_outcome = 12,
                      formula(~1 | Study))                        # n_outcome = 13
# - = change of model not recommended 
# Study = can be a Study only analysis
# null = random effects could be omitted according to Likelihood ratio tests
```

# Extended possible random factors

Particle Material: Due to chemical composition

```{r}
columns = c("LRT (PM)","pval (PM)") 
rst_tbl = data.frame(matrix(nrow = 0, ncol = length(columns))) 
colnames(rst_tbl) = columns

for(n_outcome in sequence(nlevels(outcomeslist)))
  {
  skip_to_next <- FALSE
  
  df1 <- select(df_original,c("StudyCluster","Study","Year",
                     "EScluster","Species","ParticleMaterial","yi","vi"))
  df1<- df1[complete.cases(df1),]
  
  resRF.m3 <- rma.mv(yi, vi, 
              random = random_factors[[n_outcome]], 
              data=df1, 
              method="ML")
  
  resRF.m4 <- rma.mv(yi, vi, 
              random = list(random_factors[[n_outcome]], ~ 1 | ParticleMaterial), 
              data= df1, 
              method="ML")
  
  # for ParticleMaterial versus none extra random factors with smaller data set
  if (n_distinct(df1$ParticleMaterial)>=2)
   {resRF4_3 = anova.rma(resRF.m4,resRF.m3)}
  else
   {resRF4_3$LRT  = NA
    resRF4_3$pval = NA}
  
  rst_tbl[n_outcome,] = round(c(resRF4_3$LRT, resRF4_3$pval),3)
  #rm(list = ls(pat = "res"))
   }

rownames(rst_tbl) = outcomeslist
print(rst_tbl)

rm(list = ls(pat = "resRF"))
rm("df1")
```

### Conclusion

Even if particle material could contribute with the random effects term,
on this data set its contribution is not significant to justify the
increase in the model complexity.

## Random Effects model

SYRCLE PROTOCOL: A meta-analysis will be performed with a minimum of 5
studies for the same outcome.

Criteria achieved to total studies level for all variables

```{r}
# Create variable to store random effects with robust variance estimation models
res.rob_random_effects = vector("list",nlevels(outcomeslist))
heterogeneity = vector("list",nlevels(outcomeslist))

columns = c("k estimates","N studies","ES","SE","ci.lb","ci.ub","pi.lb","pi.ub","IÂ² total","Q","Q p-value") 
#columns = c("k estimates","N studies","ES","SE","ci.lb","ci.ub","pi.lb","pi.ub","IÂ² total") 
predicted_intervals = data.frame(matrix(nrow = 0, ncol = length(columns))) 
colnames(predicted_intervals) = columns

# Select data
for(n_outcome in sequence(nlevels(outcomeslist)))
{
  df <- df_original[ which(df_original$Outcome==outcomeslist[n_outcome] ),]
  df <-df[order(df$DevelopmentalStage,-df$yi),]
  
  # fit multivariate/multilevel model with appropriate fixed/random effects
  res <- rma.mv(yi, vi,
              random = random_factors[[n_outcome]],
              data=df, 
              slab = Study,
              method="REML",  
              test="t", dfs="contain", level=95)
  
  # apply cluster-robust inference methods (robust variance estimation) using the improved methods from the clubSandwich package
  res.rob_random_effects[[n_outcome]] <- robust(res, cluster = res$mf.r[[1]][,1], clubSandwich = TRUE)

 # Heterogeneity
 heterogeneity[[n_outcome]]= round(i2_ml(res.rob_random_effects[[n_outcome]]),2)
  
  # compute predicted outcomes (with corresponding CIs) as needed
  pi <- predict(res.rob_random_effects[[n_outcome]])
  predicted_intervals[n_outcome,] <- round(c(res.rob_random_effects[[n_outcome]]$k,
                                             res.rob_random_effects[[n_outcome]]$n,
                                             pi$pred, pi$se, pi$ci.lb, pi$ci.ub, pi$pi.lb, pi$pi.ub, 
                                             heterogeneity[[n_outcome]][[1]],
                                             res.rob_random_effects[[n_outcome]]$QE, res.rob_random_effects[[n_outcome]]$QEp
                                             ),2)
  # test sets of coefficients / linear combinations as needed
  # anova(res_rob)
}

predicted_intervals = cbind(outcomeslist,predicted_intervals)
print(predicted_intervals)

#Heterogeneity1 = as.data.frame(do.call(rbind, heterogeneity[1]))
#Heterogeneity1 = cbind(outcomeslist[1],Heterogeneity1)
#print(Heterogeneity1)

Heterogeneity2 = as.data.frame(do.call(rbind, heterogeneity[c(3,13)]))
Heterogeneity2 = cbind(outcomeslist[c(3,13)],Heterogeneity2)
print(Heterogeneity2)

Heterogeneity3 = as.data.frame(do.call(rbind, heterogeneity[c(1:2,4:12)]))
Heterogeneity3 = cbind(outcomeslist[c(1:2,4:12)],Heterogeneity3)
print(Heterogeneity3)

#for(n_outcome in sequence(nlevels(outcomeslist)))
#{forest_plot(res.rob_random_effects[[n_outcome]],outcomeslist[[n_outcome]],"REmodel")}


I_yposition = c(-20,20,-10,5,10,15,20,5,-5,1,0.5,5,5)
for(n_outcome in sequence(nlevels(outcomeslist)))
{ 
  pdf(file=paste('Figures/Orchard',n_outcome,outcomeslist,'REmodel','.pdf',sep="_"),width=4,height=6) #nÃ£o funciona, nÃ£o sei pq
  orchardRE_model(res.rob_random_effects,n_outcome,I_yposition,heterogeneity)
  dev.off()
 }
```

## Multilevel Model (multilevel model)+ Moderators (multilevel mixed-effects model or multilevel meta-regression model)

# Multilevel Model

Level 1 - Sampling 
Level 2 - Effect size cluster: within studies variability
Level 3 - Study cluster: between studies variability orchard
plot displays the prediction interval of the overall effect (bold
whiskers), the number of effect sizes (k) and the number of studies (the
number in the bracket).

# Possible moderators or fixed effects to be evaluated as souces of heterogeneity

*neurobiological* - developmental stage (DevelopmentalStage) **- species
(Species) - sex (Sex) *methodological* - dose (Concentration_mg_L)**  -
rota de administracÃ£o (AdministrationRoute) - particle - material
(ParticleMaterial) - shape (ParticleShape) - size (ParticleSizeMean) **-
exposure duration (ExposureDurationDays)** *sociological* - publication
bias (se[i] as moderator) - publication year (for publication bias?)

\*\* choosed to evaluate

"A random meta-regression requires each of its moderators to have at
least five studies, multilevel needs to be evaluated"

SYRCLE PROTOCOL: Metarregression will be used for outcomes with at least
10 experiments.

DROP: GSH content, Speed during feeding, Predatory Performance

### Correlation between moderators

As multilevel models are sensitive to correlated variables, the chosen
variables must be evaluated. --\> de onde saiu essa
informaÃ§Ã£o??????????????????????????????????????????????????????????????
Outra abordagem --\>
<https://link.springer.com/article/10.3758/s13428-020-01360-0>

```{r}
moderators <- moderatorslist[c(3,9,6,8)]
model_mods = as.formula( ~ ExposureDurationDays + DevelopmentalStage + DevelopmentalStage*ExposureDurationDays
              + ParticleSizeMean + Concentration_mg_L -1)
```

```{r}
# Create variable to store random effects with robust variance estimation models
res.meta = vector("list",nlevels(outcomeslist))
heterogeneity = vector("list",nlevels(outcomeslist))
pi = vector("list",nlevels(outcomeslist))
pi = vector("list",nlevels(outcomeslist))

# Select data
for(n_outcome in sequence(nlevels(outcomeslist)))
{
  print(paste("** Meta-regresion",outcomeslist[n_outcome],"**"))
  
  df <- df_original[ which(df_original$Outcome==outcomeslist[n_outcome] ),]
  df <-df[order(df$DevelopmentalStage,-df$yi),]
  df1 <- select(df, c("StudyCluster", "Study", "EScluster", moderatorslist[c(3,9,6,8)],"yi", "vi"))
  df<- df[complete.cases(df1),]
  
  # fit multivariate/multilevel model with appropriate fixed/random effects
  res.meta[[n_outcome]] <- rma.mv(yi, vi,
                            random = random_factors[[n_outcome]],
                            mods = model_mods,
                            data=df, 
                            slab = Study,
                            method="REML",  
                            test="t", dfs="contain", level=95)
  # apply cluster-robust inference methods (robust variance estimation) using the improved methods from the clubSandwich package
  res.meta[[n_outcome]] <- robust(res.meta[[n_outcome]], cluster = res.meta[[n_outcome]]$mf.r[[1]][,1], clubSandwich = TRUE)

  # Heterogeneity
  heterogeneity[[n_outcome]]= round(i2_ml(res.meta[[n_outcome]]),2)
  
  # compute predicted outcomes (with corresponding CIs) as needed
  pi[[n_outcome]] <- predict(res.meta[[n_outcome]])

  #Goodness-of-fit index
  r2[[n_outcome]] <- r2_ml(res.meta)

  # test sets of coefficients / linear combinations as needed
  # anova(res_rob)
  
  forestmeta_plot(res.meta[[n_outcome]],outcomeslist[[n_outcome]],"FullMetaModel",model_mods)
}
#paste(format(r2[1]*100,digits=4), "% of the variation among effect sizes is explained by",formula(res_meta))

for(n_outcome in sequence(nlevels(outcomeslist)))
{
  orchard_plot(res.rob_random_effects[[n_outcome]], xlab = "Standardised mean difference", transfm = "none")}

```
